---
title: "Paper Reading Week1"
description: "10/11-10/17"
pubDate: "Oct 13 2025"
image: https://tc.alcy.cc/q/20250908/ca3053a035cbc492db167dd15acd2cb3.webp
categories:
  - Paper Reading
tags:
  - Paper
  - llm agent
---
# 论文信息 
>[Arxiv ID](https://arxiv.org/pdf/2305.10601)

>[幻觉翻译](https://hjfy.top/arxiv/2305.10601)
## Title:**Tree of Thoughts: Deliberate Problem Solving with Large Language Models 树状思维：大型语言模型的深思熟虑问题求解**


### **1. Introduction**

介绍了当前大语言模型（如GPT-4）在推理时仅限于"**从左到右、逐词生成**"的局限性，并将其类比为人类认知中的“系统1”（快速、自动）。受人类“系统2”（慢速、深思熟虑）和早期人工智能“问题求解即搜索”思想的启发，提出了“**思维树**”框架，旨在让模型能够进行探索、前瞻和回溯等更复杂的决策过程。

### **2. Background**

- Input-output (IO) prompting（输入-输出提示）： 最基本的直接生成答案的方法。

- Chain-of-thought (CoT) prompting（思维链提示）： 通过生成一系列中间推理步骤来连接输入和输出。

- Self-consistency with CoT (CoT-SC)（思维链自洽）： 通过采样多条思维链并取多数答案作为最终结果的集成方法。

### **3. Tree of Thoughts（ToT）**

![对比图片](https://github.com/lnscq/picx-images-hosting/raw/master/image.70aq76hmqt.webp)

将问题视为对一棵树的搜索，每个节点存储一个状态。

**ToT** 回答四个问题：

1 **如何将中间过程分解为思维步骤？**
> 根据具体问题的性质，将整个问题解决过程分解为多个连贯的中间步骤，每个步骤称为一个“思维”

2 **如何从每个状态生成潜在的思维？**
> 在树中的每个状态（即当前的部分解决方案）下，生成 k 个可能的后续“思维”。论文提出了两种策略：
 
  - 采样： 从思维链提示中独立同分布地采样 k 个思维。适用于思维空间丰富的情况（如生成段落计划）。

  - 提议： 使用一个“提议提示”，让模型在同一个上下文中连续生成 k 个不同的思维。适用于思维空间受限的情况（如生成一个单词或一行方程），以避免重复。

3 **如何启发式地评估状态？**

> 不使用传统的搜索算法，而是用**LLM**对节点状态进行评估打分，好处是比编程的规则更加灵活。考虑**两种策略**对状态进行评估。

- **独立评估**： 为每个状态 $S$ 独立生成一个标量值（如1-10分）或分类（如“确定/可能/不可能”）。评估基于快速前瞻模拟和常识。
- **投票评估**： 让语言模型在多个状态 $S$ 中进行比较，并投票选出最有可能的一个。这相当于一个“逐步”的自洽性检查。




4 **使用什么搜索算法？**

- **广度优先搜索（BFS）** 每一步维持最多$b$个最有希望的状态。在深度有限的任务中使用。

- **深度优先搜索（DFS）** 首先搜索最有希望的状态，直到完成输出或者评估器认为当前$S$无法完成问题。 对该$S$的子节点进行剪枝并回溯到$S$的父节点继续搜索。

### **4. Experiment**

结果部分通过在三个精心设计的任务上的实验，得出了一个核心且一致的结论：Tree of Thoughts (ToT) 框架能够极大地提升大语言模型（GPT-4）在需要进行探索、规划和搜索的复杂任务上的性能，显著优于传统的输入-输出（IO）提示、思维链（CoT）提示以及思维链自洽（CoT-SC）等基线方法。

#### **消融实验**
- 无剪枝
- 无回溯

## 论文信息 
>[Arxiv ID](https://arxiv.org/pdf/2210.03629)

>[幻觉翻译](https://hjfy.top/arxiv/2210.03629)
### **Title:ReAct: Synergizing Reasoning and Acting in Language ModelsReAct: 在语言模型中协同推理和行动**
## 论文结构

### **1. Introduction**

当前的大语言模型在解决复杂任务时，其"推理"和"行动"能力是相互割裂的。纯推理方法容易产生事实幻觉且无法获取最新信息，而纯行动方法缺乏战略规划能力，容易在复杂任务中迷失方向。提出了 **ReAct范式**，通过在大语言模型中交织生成**推理轨迹**和**任务特定动作**，创建"推理指导行动，行动辅助推理"的协同机制，使模型能够动态规划、利用外部信息并处理异常。


### **2. Background**

- **Standard prompting（标准提示）**： 直接生成答案或行动，缺乏显式推理过程。

- **Chain-of-Thought (CoT) prompting（思维链提示）**： 通过生成推理步骤提升模型表现，但是**静态的、封闭的**，无法与外部环境交互，容易产生**事实幻觉**和**错误传播**。

- **Act-only prompting（纯行动提示）**： 能够与环境交互，但缺乏**高层次的语言推理**来指导行动规划、跟踪进度和处理异常。

### **3. ReAct**

![ReAct对比图](https://github.com/lnscq/picx-images-hosting/raw/master/image.3k8egkob9t.webp)

将任务求解视为在推理空间和行动空间中的交替执行过程。

**ReAct** 解决四个关键问题：

1 **如何融合推理与行动？**
> 通过扩展智能体的行动空间至 $\hat{\mathcal{A}} = \mathcal{A} \cup \mathcal{L}$，其中 $\mathcal{A}$ 是外部行动空间（如搜索、点击），$\mathcal{L}$ 是语言（推理）空间。模型可以交替或按需生成"思考"和"行动"。

2 **如何设计任务特定的行动空间？**
> 根据任务需求设计最小化但足够的行动集：
  - **知识任务**：搜索(Search)、查找(Lookup)、完成(Finish)
  - **决策任务**：导航(Go to)、拿取(Take)、使用(Use)等环境原生动作
  - **网页任务**：搜索(Search)、点击(Click)、购买(Buy Now)

3 **如何生成有效的推理轨迹？**
> 通过少量示例提示，引导模型生成多种类型的推理：
  - **任务分解**："我需要先搜索X，然后查找Y"
  - **信息提取**："段落中提到成立于1844年"
  - **进度跟踪**："现在生菜已清洗，下一步是放到餐桌"
  - **异常处理**："搜索无结果，尝试换关键词"
  - **常识推理**："台灯通常放在桌子或架子上"

4 **如何平衡推理与行动的密度？**
> 根据任务类型动态调整：
>  - **知识密集型任务**：采用**密集、交替** 的思考-行动-观察步骤
>  - **决策制定任务**：采用**稀疏、按需**的思考，在关键时刻（如规划、遇到困境时）进行推理

### **4. 实验验证**

通过在四个不同领域的基准测试上的实验，证明了ReAct框架的显著优势：

- **知识推理任务**（HotpotQA, FEVER）：
  - ReAct优于纯行动方法，展示了推理对行动的指导价值
  - 与CoT相比，ReAct减少了幻觉，提高了事实准确性
  - ReAct + CoT-SC组合达到了最佳性能，结合了内部知识和外部信息

- **交互决策任务**（ALFWorld, WebShop）：
  - **少量提示**的ReAct显著超越了需要**大量专家数据**训练的模仿学习和强化学习方法
  - 在ALFWorld上绝对成功率提升34%，在WebShop上提升10%
  - 纯行动基线容易陷入循环或迷失方向，而ReAct能有效规划并跟踪目标

#### **消融与分析**
- **与Inner Monologue对比**：ReAct的**主动推理**优于单纯复述环境反馈
- **错误模式分析**：ReAct的失败更多源于推理错误或搜索无效，而非事实幻觉
- **人机回环验证**：人类通过编辑推理轨迹可轻松纠正模型行为，证明了框架的可控性

### **5. 核心贡献总结**

1. **范式创新**：首次系统性地将推理与行动在LLM中协同，提出统一框架
2. **通用性强**：在知识推理和交互决策两大类任务上均表现优异
3. **实用性突出**：通过提示方法实现，成本低且易于复现
4. **可解释性佳**：生成的推理轨迹提供透明的问题解决过程
5. **开辟新方向**：为构建更可靠、可控的AI智能体奠定了基础
