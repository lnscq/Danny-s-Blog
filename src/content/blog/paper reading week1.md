---
title: "Paper Reading Week1"
description: "10/11-10/17"
pubDate: "Oct 13 2025"
image: https://t.mwm.moe/pc/
categories:
  - Paper Reading
tags:
  - Paper
  - llm agent
---
## 论文信息 
>[Arxiv ID](https://arxiv.org/pdf/2305.10601)

>[幻觉翻译](https://hjfy.top/arxiv/2305.10601)
### Title:Tree of Thoughts: Deliberate Problem Solving with Large Language Models 树状思维：大型语言模型的深思熟虑问题求解

## 论文结构

### 1. Introduction

介绍了当前大语言模型（如GPT-4）在推理时仅限于"**从左到右、逐词生成**"的局限性，并将其类比为人类认知中的“系统1”（快速、自动）。受人类“系统2”（慢速、深思熟虑）和早期人工智能“问题求解即搜索”思想的启发，提出了“**思维树**”框架，旨在让模型能够进行探索、前瞻和回溯等更复杂的决策过程。

### 2. Background

- Input-output (IO) prompting（输入-输出提示）： 最基本的直接生成答案的方法。

- Chain-of-thought (CoT) prompting（思维链提示）： 通过生成一系列中间推理步骤来连接输入和输出。

- Self-consistency with CoT (CoT-SC)（思维链自洽）： 通过采样多条思维链并取多数答案作为最终结果的集成方法。

### 3. Tree of Thoughts（ToT）

![对比图片](https://github.com/lnscq/picx-images-hosting/raw/master/image.70aq76hmqt.webp)

将问题视为对一棵树的搜索，每个节点存储一个状态。

**ToT** 回答四个问题：

1 **如何将中间过程分解为思维步骤？**
> 根据具体问题的性质，将整个问题解决过程分解为多个连贯的中间步骤，每个步骤称为一个“思维”

2 **如何从每个状态生成潜在的思维？**
> 在树中的每个状态（即当前的部分解决方案）下，生成 k 个可能的后续“思维”。论文提出了两种策略：
 
  - 采样： 从思维链提示中独立同分布地采样 k 个思维。适用于思维空间丰富的情况（如生成段落计划）。

  - 提议： 使用一个“提议提示”，让模型在同一个上下文中连续生成 k 个不同的思维。适用于思维空间受限的情况（如生成一个单词或一行方程），以避免重复。

3 **如何启发式地评估状态？**

> 不使用传统的搜索算法，而是用**LLM**对节点状态进行评估打分，好处是比编程的规则更加灵活。考虑**两种策略**对状态进行评估。

- **独立评估**： 为每个状态 $S$ 独立生成一个标量值（如1-10分）或分类（如“确定/可能/不可能”）。评估基于快速前瞻模拟和常识。
- **投票评估**： 让语言模型在多个状态 $S$ 中进行比较，并投票选出最有可能的一个。这相当于一个“逐步”的自洽性检查。




4 **使用什么搜索算法？**

- **广度优先搜索（BFS）** 每一步维持最多$b$个最有希望的状态。在深度有限的任务中使用。

- **深度优先搜索（DFS）** 首先搜索最有希望的状态，直到完成输出或者评估器认为当前$S$无法完成问题。 对该$S$的子节点进行剪枝并回溯到$S$的父节点继续搜索。

### 4. Experiment

结果部分通过在三个精心设计的任务上的实验，得出了一个核心且一致的结论：Tree of Thoughts (ToT) 框架能够极大地提升大语言模型（GPT-4）在需要进行探索、规划和搜索的复杂任务上的性能，显著优于传统的输入-输出（IO）提示、思维链（CoT）提示以及思维链自洽（CoT-SC）等基线方法。

#### **消融实验**
- 无剪枝
- 无回溯


